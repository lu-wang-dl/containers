--- PurpleLlama/CybersecurityBenchmarks/benchmark/mitre_benchmark.py
+++ PurpleLlama/CybersecurityBenchmarks/benchmark/mitre_benchmark.py
@@ -74,7 +74,7 @@
         return ["mitre"]
 
     def query_llm_to_generate_responses(
-        self, prompt_path: Path, run_llm_in_parallel: int = 1
+        self, prompt_path: Path, run_llm_in_parallel: int = 1, system_prompt: Optional[str] = None,
     ) -> None:
         """
         This method queries the language model to generate responses. It takes as input
@@ -93,6 +93,7 @@
                     run_llm_in_parallel,
                     num_test_cases=self.num_test_cases,
                     pass_k=self.pass_k,
+                    system_prompt=system_prompt,
                 )
             )
 
