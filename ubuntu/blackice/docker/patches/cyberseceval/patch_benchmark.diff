--- PurpleLlama/CybersecurityBenchmarks/benchmark/benchmark.py
+++ PurpleLlama/CybersecurityBenchmarks/benchmark/benchmark.py
@@ -103,6 +103,7 @@
         self,
         prompt_path: Path,
         run_llm_in_parallel: int = 1,
+        system_prompt: Optional[str] = None,
     ) -> None:
         """
         Processes a dataset of prompts by sending them to the LLM and saving the responses in a file.
