--- PurpleLlama/CybersecurityBenchmarks/benchmark/prompt_injection_benchmark.py
+++ PurpleLlama/CybersecurityBenchmarks/benchmark/prompt_injection_benchmark.py
@@ -55,7 +55,7 @@
         return ["prompt-injection"]
 
     def query_llm_to_generate_responses(
-        self, prompt_path: Path, run_llm_in_parallel: int = 1
+        self, prompt_path: Path, run_llm_in_parallel: int = 1, system_prompt: Optional[str] = None,
     ) -> None:
         """
         Processes a dataset of prompts by sending them to the LLM and saving the responses in a file.
@@ -71,6 +71,7 @@
                     to_process_prompt=process_prompt_and_user_input,
                     num_test_cases=self.num_test_cases,
                     pass_k=self.pass_k,
+                    system_prompt=system_prompt,
                 )
             )
 
