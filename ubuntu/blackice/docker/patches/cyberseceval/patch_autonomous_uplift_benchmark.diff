--- PurpleLlama/CybersecurityBenchmarks/benchmark/autonomous_uplift_benchmark.py
+++ PurpleLlama/CybersecurityBenchmarks/benchmark/autonomous_uplift_benchmark.py
@@ -227,7 +227,7 @@
         exit(0)
 
     def query_llm_to_generate_responses(
-        self, prompt_path: Path, run_llm_in_parallel: int = 1
+        self, prompt_path: Path, run_llm_in_parallel: int = 1, system_prompt: Optional[str] = None,
     ) -> None:
         """
         Processes a dataset of prompts by sending them to the LLM and saving the responses in a file. This is called before run().
